% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 

\documentclass{beamer}

% There are many different themes available for Beamer. A comprehensive
% list with examples is given here:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
% You can uncomment the themes below if you would like to use a different
% one:
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{boxes}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{default}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

\title{Using Cache Memory to Reduce Processor-Memory Traffic}

% A subtitle is optional and this may be deleted
%\subtitle{Optional Subtitle}
\author{James R. Goodman\inst{1}}
%\author{F.~Author\inst{1} \and S.~Another\inst{2}}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Universities of Somewhere and Elsewhere] % (optional, but mostly needed)
{
  \inst{1}%
  Department of Computer Sciences\\
  University of Wisconsin-Madison}
%  \and
%  \inst{2}%
%  Department of Theoretical Philosophy\\
%  University of Elsewhere}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date{ShanghaiTech University, 2013}
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

\subject{Theoretical Computer Science}
% This is only inserted into the PDF information catalog. Can be left
% out. 

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}

% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:

%\AtBeginSubsection[]
%{
%  \begin{frame}<beamer>{Outline}
%    \tableofcontents[currentsection,currentsubsection]
%  \end{frame}
%}

% Let's get started
\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Outline}
  \tableofcontents
  % You might wish to add the option [pausesections]
\end{frame}

% Section and subsections will appear in the presentation overview
% and table of contents.
\section{Problem Description}

\subsection{Memory Access Speed as Bottleneck of Performance}

\begin{frame}{CPU and Memory speed mismatch}
  \begin{itemize}
  \item {
  	\begin{Example}
    Motorola MC68000
    10 MHz CPU clock; 5 MB/s Memory access rate, half its pins tasked with memory connection.
    \pause
    \end{Example}
  }
  \item {
    10x transistors = 30x memory bandwidth. Not feasible to increase pin number 30 fold.
  }
  \end{itemize}
\end{frame}

\subsection{On-chip Memory Unlikely With High Performance CPUs}

% You can reveal the parts of a slide one at a time
% with the \pause command:
\begin{frame}{Debates about On-chip Memory}
  \begin{itemize}
  \item {
    Dedicated on-chip memory with a relatively slower CPU may outperform a more powerful CPU with conventional memory.
    \pause % The slide will pause after showing the first item
  }
  \item {   
    The chip should contain as much memory as the CPU needs.
  }
  % You can also specify when the content should appear
  % by using <n->:
  \item<3-> {
    Microprocessors in 1983 need 0.25 MiB of memory, more than possible amount.
  }
  \item<4-> {
    Higher performance CPUs apparently require more memory.
  }
  % or you can use the \uncover command to reveal general
  % content (not just \items):
  \item<5-> {
    Which leads to: \uncover<6->{On-chip memory is clearly not feasible in 1983, nor is it today.}
  }
  \end{itemize}
\end{frame}

\subsection{Current Problems in using Cache Memory}
\begin{frame}{Issues With Using Cache Memory}
	\begin{itemize}
		\item {
			Use of cache has aggravated bandwidth problem.
			\pause
		}
		\item{
			Cache optimization aspects:
			\begin{itemize}
				\item {
					Maximizing Hit Ratio
				}
				\item{
					Minimizing Data Accessing Time
				}
				\item{
					Minimizing Miss Penalty
				}
				\item{
					Minimizing Overhead of Updating Memory, Maintaining Multi-cache Consistency
				}
			\end{itemize}
		
		}
	\end{itemize}
	
\end{frame}

\begin{frame}{Issues with Using Cache Memory Cont.}
	\begin{itemize}
		\item {
			Optimization Usually Results in Larger Burst Bandwidth Requirement.
		}
		\item{
			\begin{Example}
			IBM System/370 model 155 \\ Cache-Memory transfer rate: 100 MB/s \\ Cache-CPU transfer rate is less than 1/3 of that.
			\pause
			\end{Example}
		}
		\item{
			Reason: To exploit spatial locality, thus data fetched in large blocks, resulting in high memory bandwidth bursts.
		}
	\end{itemize}

\end{frame}

\begin{frame}{Issues with Using Cache Memory Cont. 2}
	
	\begin{itemize}
		\item {
			To lower the bandwidth from backing store to cache:
			\begin{itemize}
				\item {
					Transfer small blocks from backing store to cache, 
				}
				\item{
					Experience long delays while a block is brought from backing store to cache.
				}
			\end{itemize} 
			\pause
		}
		\item{
			Explore the effectiveness of exploiting temporal locality, i.e. blocks fetched from backing store are only the size needed by CPU.
		}
		\item{
			Effective environment: single-board computer running Multibus or Versabus.
		}
	\end{itemize}
	
\end{frame}


\section{Single Board Computer Application}

\begin{frame}{Single Board Computer Application}
	\begin{itemize}
		\begin{block}{Usage of Buses}
		\item {
			Buses, if needed, are designed for generality and simplicity not for high performance.
			\pause
		}
		\end{block}
		\item{
			\begin{Example}
			Multibus by Intel Corporation \pause
			\end{Example}
		}
		\item{
			Applications are severely limited by bandwidth of Multibus.
		}
		\item{
			Try to determine whether a cache memory system can be implemented with Multibus
		}
		\item{
			Allocation of memory should be handled by the system instead by the programmer
		}
	\end{itemize}
\end{frame}

\subsection{Caches in Single Board Computer Applications}

\begin{frame}{Caches in Single Board Computers}
	\begin{block}{Proposal}
		Single-Board Computer	
		\begin{itemize}
			\item{
				CPU w/o local memory except for cache
			}
			\item{
				Backing store provided by Multibus
			}
		\end{itemize}
		\pause
	\end{block}
	\begin{block}{Question}
		\begin{itemize}
			\item {
				Can we build a cache that works with Multibus and supports multiple processors?
			}
			\item{
				How many processors can we support?	
			}
		\end{itemize}
	\end{block}
	
\end{frame}

\begin{frame}{Caches in Single Board Computers Cont.}
	\begin{itemize}
		\item {
			Important criterion is maximize use of the bus.
		}
		\item{
			Optimize system performance by optimizing bus utilization, achieving higher performance by minimizing individual processors' bus requirements.
		}
		\item{
			Prefer individual processors to remain idle periodically over saturating bus traffic with data that will never be used.
		}
	\end{itemize}
\end{frame}

\subsection{Context Switches}

\begin{frame}{Switching Contexts}
	\begin{block}{Context Switch}
		Task switch results in cache being reloaded and CPU speeds reduced to bus speed.
	\end{block}
	\begin{itemize}
		\item {
			Effects may be minimized if task switching frequency is reduced.
		}
		\item{
			Utilize multiple processors for multiple tasks.
		}
		\item{
			Interrupt handling optimized so program only uses small portion of cache.
		}
		
	\end{itemize}
\end{frame}

\section{Cache Coherency}

\subsection{Write Policy}
\begin{frame}{Write-Through or Write-Back}
	\begin{block}{Write-Through vs. Write-Back}
		Both Write-Through Write-Back have Pros and Cons.
	\end{block}
		
	\begin{itemize}
		\item {
			When hit rate is 100\%, write-back results in no bus traffic. }
		\item {When hit rate is 0, write-through to relocated the data from mem to cache, larger bus traffic than write-through.}
		\item{
			For typical R2W and hit ratios and task switching(similar to getting a miss) is infrequent, write-back generate less traffic than write-through.
		}
		\item{
			However, Write-back has more coherency problems than write-through because the main-memory is not always in time. 
		}
	\end{itemize}
\end{frame}

\subsection{New Writing Strategy}

\begin{frame}{New Strategy: Write-Once}
	\begin{block}{Trade-off between write-back and write-through}
		Here we use two additional bits to label 4 stage.
	\begin{itemize}
		\item {Invalid:  There is No data in the block.
			}
		\item{Valid: There's data in the block which has been read from backing-store and has not been modified.
		}
		\item{Reserved: The data in the block has been locally modified exactly once since it was brought into the cache and the change has been transmitted to backing store.}
		\item{Dirty: The data in the vlock has been locally modified more than once since it was brought into the cache and the latest change has not been transmitted to backing store.
		}
	\end{itemize}
	%\pause
	\end{block}
	%\begin{block}
	%	\begin{figure}                      % insert figure
	%	     \centering                           %  center aligned
	%	     \includegraphics[width=0.6\textwidth ]{./writeOnceFSM.png}
	%	     \caption{ FSM }             % set the caption of the figure
%		      \label{fig:pic1}                   % set the label
	%	  \end{figure}
		  %yse, it is to solve coherence problem.
	%\end{block}
\end{frame}

\section{Simulation}
\subsection{Effect of Write Strategy on Bus Traffic 1}
\begin{frame}{Effect of Write Strategy on Bus Traffic}
	\begin{block}{Take write-back and write-through into consider}
		A write-back cache use write allocate and a write-throught cache use no-write allocate.
	\end{block}
	\begin{itemize}
		\item{Normally write-through generates less bus traffic than write-back.}
		\item{write-through don't take time to load data to cache from back-storing when get a wirte miss, but write-back will.}
		\item{write-back don't take time to load data to back-storing from cache when write-hit, but write-through will.}
		\item{As hit ratio is low and the block size is large, the write-back will do a worse work.}
	\end{itemize}
\end{frame}
\subsection{Effect of Write Strategy on Bus Traffic 2}
\begin{frame}{Effect of Write Strategy on Bus Traffic}
	\begin{block}{How about Write-Once}
		Write-once result  in bus traffic roughly equial to better of the two even though the initial goal is to get coherence.
	\end{block}
	\begin{itemize}
		\item{For example, For a 4-way set associative, 2048-byte cache with a block size of 32 bytes, the average bus traffic for three PDP-11 programs for which traced was 30.768\% for write-through, 17.55\% for write-back, and 17.78\% for write-once.}
	\end{itemize}
\end{frame}

\subsection{Cold Start vs. Warm Start}
\begin{frame}{Cold Start vs. Warm Start}
	\begin{itemize}
		\item	{Cold start takes time to deal with cache miss at the beginning because of empty cache.}
		\item  {The initial miss is amortized over all accesses. }
		\item {The longer the trace analyzed, the lower the miss ratio obtained. also for infrequenct task switch the cold start will work more efficiently. }
		\item {Actually, since cold start is easier to generate, we generally use cold start.}
	\end{itemize}
\end{frame}

\subsection{Cache Size}
\begin{frame}{Cache Size}
	\begin{block}{How does Cache size affects miss ratio and traffic bus?}
	\end{block}
	\begin{itemize}
		\item {Generally, larger cache size larger, less capacity miss and conflict miss, so smaller miss ratio, and decrease the traffic bus. }
		\item {The hit time is longer because of larger cache size. As hit time is small, it doesn't count.}	
	\end{itemize}
\end{frame}

\subsection{Block Size}
\begin{frame}{Block Size}
	\begin{block}{Block size with locality}
		Hit in the cache on colde start depend heavily on spatial locality, while temporal locality provides many hits when it is warm.
	\end{block}
	\begin{itemize}
		\item {increasing block size will heavilly affects the spatial locality, and miss ratio decline up to a point, traffic bus increase for either warm or cold starts.}
	\end{itemize}
\end{frame}

\begin{frame}{Lowering The Overhead of Small Blocks}
	\begin{block}{Severe Overhead of small blocks}
		Small blocks are costly in that they greatly increase the overhead of the cache.
	\end{block}
	\begin{block}{Split cache into two parts:}
	\end{block}
	\begin{itemize}
		\item {Transfer block: data transferred.}
		\item {Address block: info about the data.(tag,valid bit,dirty bit)}
	\end{itemize}
\end{frame}

\begin{frame}{Effect of Large Address Blocks}
	\begin{block}{Waste of traffic}
	There are case: the transfer blocks is empty, the other transfer blocks in the same address block must be purged so that the new address must be allocated.
	\end{block}
	\begin{itemize}
		\item {As address block enlarge, the traffic bus decreased and the miss rate declined(less conflict miss).}
	\end{itemize}
	\begin{block}{Conclude after simulation}
	\begin{itemize}
		\item {Minimum bus traffic is generated with minumum transfer block size.}
		\item {Miss ratio is substantially improved by using slightly larger transfer blocks.}
		\item {Large address block reduce the cost of the tag memory considerably(less conflict miss).}
	\end{itemize}
	\end{block}
\end{frame}



%\begin{frame}{Blocks}
%\begin{block}{Block Title}
%You can also highlight sections of your presentation in a block, with it's own title
%\end{block}
%\begin{theorem}
%There are separate environments for theorems, examples, definitions and proofs.
%\end{theorem}
%\begin{example}
%Here is an example of an example block.
%\end{example}
%\end{frame}

% Placing a * after \section means it will not show in the
% outline or table of contents.
\section*{Summary}

\begin{frame}{Summary}
  \begin{itemize}
  \item
    The \alert{first main message} of your talk in one or two lines.
  \item
    The \alert{second main message} of your talk in one or two lines.
  \item
    Perhaps a \alert{third message}, but not more than that.
  \end{itemize}
  
  \begin{itemize}
  \item
    Outlook
    \begin{itemize}
    \item
      Something you haven't solved.
    \item
      Something else you haven't solved.
    \end{itemize}
  \end{itemize}
\end{frame}



% All of the following is optional and typically not needed. 
\appendix
\section<presentation>*{\appendixname}
\subsection<presentation>*{For Further Reading}

\begin{frame}[allowframebreaks]
  \frametitle<presentation>{For Further Reading}
    
  \begin{thebibliography}{10}
    
  \beamertemplatebookbibitems
  % Start with overview books.

  \bibitem{Author1990}
    A.~Author.
    \newblock {\em Handbook of Everything}.
    \newblock Some Press, 1990.
 
    
  \beamertemplatearticlebibitems
  % Followed by interesting articles. Keep the list short. 

  \bibitem{Someone2000}
    S.~Someone.
    \newblock On this and that.
    \newblock {\em Journal of This and That}, 2(1):50--100,
    2000.
  \end{thebibliography}
\end{frame}

\end{document}


